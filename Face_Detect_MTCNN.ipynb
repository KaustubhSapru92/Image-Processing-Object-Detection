{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the libraries\n",
    "import cv2 \n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cap = cv2.VideoCapture('C:\\\\Users\\\\lenovo\\\\Downloads\\\\The_Big_Sick-ch1.avi') #load the video by specifying the video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "detector = MTCNN(keep_all =True, post_process=False, device = device) #initialize the face detector on the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displayes the frames with bounding boxes in a window \n",
    "def show_faces(frames,predictions,i,show):\n",
    "    if show == True:\n",
    "        I = np.asarray(frames[i].resize([int(f * 4) for f in frame.size]))\n",
    "        I = cv2.cvtColor(I, cv2.COLOR_RGB2BGR)\n",
    "        if type(predictions[i]) == np.ndarray:\n",
    "            for k in range(len(predictions[i])):\n",
    "                x1,y1,x2,y2 = predictions[i][k]\n",
    "                cv2.rectangle(I,(int(x1*4),int(y1*4)),(int(x2*4),int(y2*4)),(255,255,0),2)\n",
    "\n",
    "        cv2.imshow('Video',I)\n",
    "        cv2.putText(I, f'face detected',(20,70),cv2.FONT_HERSHEY_PLAIN, 3,(255,255,0),2)\n",
    "\n",
    "#saves bounding boxes in a dataframe     \n",
    "def save_coordinates(dataframe,predictions,j,a):\n",
    "    \n",
    "    dataframe.Frames.iloc[j] = 'frame{}'.format(j)\n",
    "    dataframe.Coordinates.iloc[j] = predictions[a]\n",
    "           \n",
    "    if type(predictions[a]) == np.ndarray:\n",
    "        b = []\n",
    "        for y in range(len(predictions[a])):\n",
    "            b.append('face{}'.format(y+1))\n",
    "        dataframe.Faces.iloc[j] = b\n",
    "    else:\n",
    "        dataframe.Faces.iloc[j] = []\n",
    "                \n",
    "    dataframe.Width.iloc[j] = frames[a].width\n",
    "    dataframe.Height.iloc[j] = frames[a].height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing variables\n",
    "batch_size = 32\n",
    "frames = []\n",
    "v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "c=0\n",
    "p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing a dataframe\n",
    "data = pd.DataFrame(index = np.arange(v_len),columns=['Frames','Faces','Coordinates','Width','Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a5ccd1a7d842e29a35812397aefdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32780.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run the detector over a batch of frames\n",
    "for _ in tqdm(range(v_len)):\n",
    "    # Load frame\n",
    "    success, img = v_cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "        \n",
    "    # Add to batch, resizing for speed\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = frame.resize([int(f * 0.25) for f in frame.size])\n",
    "    frames.append(frame)\n",
    "    \n",
    "    # When batch is full, detect faces and reset batch list\n",
    "    if len(frames) >= batch_size:\n",
    "        batch_boxes, batch_probs = detector.detect(frames)\n",
    "        a=0\n",
    "        for j in range(c,p+1):\n",
    "            save_coordinates(data,batch_boxes,j,a)\n",
    "            show_faces(frames,batch_boxes,a,False)\n",
    "            a+=1\n",
    "            \n",
    "        c = c+32\n",
    "        frames = []\n",
    "        \n",
    "    p+=1    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        print('User interupt')\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Movie_Faces.csv',index=False) #save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
